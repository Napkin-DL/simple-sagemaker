{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09065721",
   "metadata": {},
   "source": [
    "# SageMaker Endpoint (Single Model Endpoint)\n",
    "---\n",
    "\n",
    "이제 **SageMaker 모델 호스팅 서비스인 SageMaker 엔드포인트**에 모델을 배포할 준비가 되었습니다. \n",
    "\n",
    "SageMaker 엔드포인트는 REST API를 통해 실시간 추론을 수행할 수 있는 완전 관리형 서비스입니다. 기본적으로 분산 컨테이너로 고가용성, 다중 모델 로딩, A/B 테스트를 위한 인프라 환경(EC2, 로드밸런서, 오토스케일링, 모델 아티팩트 로딩 등)이 사전 구축되어 있기에 몇 줄의 코드만으로 Endpoint가 자동으로 생성되기에, 모델을 프로덕션에 빠르게 배포할 수 있습니다.\n",
    "\n",
    "SageMaker 빌트인 XGBoost를 사용하면 별도의 훈련/추론 스크립트 작성 없이 쉽게 모델을 훈련하고 엔드포인트로 배포할 수 있습니다. 하지만, 여러 가지 요인들로 인해 (예: SHAP 계산을 위한 피쳐 기여값 리턴, 추론값 및 추론 스코어 동시 리턴 등) 커스텀 추론 로직이 필요한 경우, SageMaker 빌트인 XGBoost 대신 SageMaker XGBoost 컨테이너를 사용할 수 있습니다.\n",
    "\n",
    "이 노트북은 SageMaker XGBoost 컨테이너 상에서, 기본적인 추론 스크립트로 모델을 배포하는 법을 아래와 같은 목차로 진행합니다. \n",
    "\n",
    "완료 시간은 **20-30분** 정도 소요됩니다.\n",
    "\n",
    "### 목차\n",
    "- [1. Create Model Serving Script](#1.-Create-Model-Serving-Script)\n",
    "- [2. Deploy a trained model from Amazon S3](#2.-Deploy-a-trained-model-from-Amazon-S3)\n",
    "    - [2.1. Deploy to Local Environment: XGBoostModel class](#2.1.-Deploy-to-Local-Environment:-XGBoostModel-class)\n",
    "    - [2.2. Deploy to Local Environment: Model class](#2.2.-Deploy-to-Local-Environment:-Model-class)\n",
    "    - [2.3. Deploy to Hosting Instance](#2.3.-Deploy-to-Hosting-Instance)\n",
    "\n",
    "유사한 예제로 실습해 보실 분들은 아래 링크의 샘플 노트북을 참조해 주세요.\n",
    "- https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone_dist_script_mode.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2686e584",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><h4>주의</h4><p>\n",
    "아래 코드 셀은 핸즈온에 필요한 라이브러리들을 설치하고, 주피터 노트북 커널을 셧다운시킵니다. \n",
    "    \n",
    "노트북 커널이 셧다운된다면, 아래 코드 셀에서 <b><font color='darkred'>install_needed = False</font></b>로 변경 후, 코드 셀을 다시 실행해 주세요. 이 작업은 한 번만 수행하면 됩니다. \n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e3e2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%store -r\n",
    "XGB_FRAMEWORK_VERSION = '1.3-1'\n",
    "DATASET_PATH = '../data/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10bfaf7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 0. (Optional) Prepare Your Model\n",
    "---\n",
    "\n",
    "혹시 이전 과정을 다 끝내지 못했다면, 아래 코드 셀의 주석을 해제하여 코드 셀을 실행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad63102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import xgboost as xgb\n",
    "# data = pd.read_csv(f'{DATASET_PATH}/train.csv')\n",
    "# train = data.drop('fraud', axis=1)\n",
    "# label = pd.DataFrame(data['fraud'])\n",
    "# dtrain = xgb.DMatrix(train, label=label)\n",
    "\n",
    "# params = {'max_depth': 3, 'eta': 0.2, 'objective': \"binary:logistic\", 'scale_pos_weight': 29}\n",
    "# num_boost_round = 100\n",
    "# nfold = 5\n",
    "# early_stopping_rounds = 10\n",
    "\n",
    "# cv_results = xgb.cv(\n",
    "#     params = params,\n",
    "#     dtrain = dtrain,\n",
    "#     num_boost_round = num_boost_round,\n",
    "#     nfold = nfold,\n",
    "#     early_stopping_rounds = early_stopping_rounds,\n",
    "#     metrics = ('auc'),\n",
    "#     stratified = True, # 레이블 (0,1) 의 분포에 따라 훈련 , 검증 세트 분리\n",
    "#     seed = 0\n",
    "# )\n",
    "\n",
    "# print(\"cv_results: \", cv_results)\n",
    "\n",
    "# # Select the best score\n",
    "# print(f\"[0]#011train-auc:{cv_results.iloc[-1]['train-auc-mean']}\")\n",
    "# print(f\"[1]#011validation-auc:{cv_results.iloc[-1]['test-auc-mean']}\")\n",
    "\n",
    "# metrics_data = {\n",
    "#     'classification_metrics': {\n",
    "#         'validation:auc': { 'value': cv_results.iloc[-1]['test-auc-mean']},\n",
    "#         'train:auc': {'value': cv_results.iloc[-1]['train-auc-mean']}\n",
    "#     }\n",
    "# }\n",
    "      \n",
    "# model = xgb.train(params=params, dtrain=dtrain, num_boost_round=len(cv_results))\n",
    "# model.save_model(\"xgboost-model\")\n",
    "# !tar -czvf model.tar.gz xgboost-model && rm xgboost-model   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676f6fb",
   "metadata": {},
   "source": [
    "`Session()`은 AWS 환경에 접속하는 접속 정보와 SageMaker에서 사용하는 리소스를 관리하기 위한 편리한 방법을 제공합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b820e0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sagemaker-us-east-1-875385903972', 'arn:aws:iam::875385903972:role/TeamRole')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sm_session = sagemaker.session.Session()\n",
    "boto_session = boto3.session.Session()\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "bucket = sm_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto_session.region_name\n",
    "\n",
    "print((bucket, role))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c68ee3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 1. Create Model Serving Script\n",
    "\n",
    "---\n",
    "\n",
    "아래 코드 셀은 src 디렉토리에 SageMaker 추론 스크립트를 저장합니다.\n",
    "\n",
    "#### Option 1.\n",
    "- `model_fn(model_dir)`: S3의 `model_dir`에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `input_fn(request_body, content_type)`: 입력 데이터를 전처리합니다. `content_type`은 입력 데이터 종류에 따라 다양하게 처리 가능합니다. (예: `application/x-npy`, `application/json`, `application/csv`등)\n",
    "- `predict_fn(input_object, model)`: `input_fn(...)`을 통해 들어온 데이터에 대해 추론을 수행합니다.\n",
    "- `output_fn(prediction, accept_type)`: `predict_fn(...)`에서 받은 추론 결과를 후처리를 거쳐 프론트엔드로 전송합니다.\n",
    "\n",
    "#### Option 2.\n",
    "- `model_fn(model_dir)`: S3의 model_dir에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `transform_fn(model, request_body, content_type, accept_type)`: `input_fn(...), predict_fn(...), output_fn(...)`을 `transform_fn(...)`으로 통합할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c3e1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/inference.py\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import xgboost as xgb\n",
    "import sagemaker_xgboost_container.encoder as xgb_encoders\n",
    "NUM_FEATURES = 58\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialize and return fitted model.\n",
    "    \"\"\"\n",
    "    model_file = \"xgboost-model\"\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(os.path.join(model_dir, model_file))\n",
    "    return model\n",
    "                     \n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    The SageMaker XGBoost model server receives the request data body and the content type,\n",
    "    and invokes the `input_fn`.\n",
    "    Return a DMatrix (an object that can be passed to predict_fn).\n",
    "    \"\"\"\n",
    "    print(\"Content type: \", request_content_type)\n",
    "    if request_content_type == \"application/x-npy\":        \n",
    "        stream = BytesIO(request_body)\n",
    "        array = np.frombuffer(stream.getvalue())\n",
    "        array = array.reshape(int(len(array)/NUM_FEATURES), NUM_FEATURES)\n",
    "        return xgb.DMatrix(array)\n",
    "    elif request_content_type == \"text/csv\":\n",
    "        return xgb_encoders.csv_to_dmatrix(request_body.rstrip(\"\\n\"))\n",
    "    elif request_content_type == \"text/libsvm\":\n",
    "        return xgb_encoders.libsvm_to_dmatrix(request_body)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Content type {} is not supported.\".format(request_content_type)\n",
    "        )\n",
    "        \n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    SageMaker XGBoost model server invokes `predict_fn` on the return value of `input_fn`.\n",
    "\n",
    "    Return a two-dimensional NumPy array (predictions and scores)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    y_probs = model.predict(input_data)\n",
    "    print(\"--- Inference time: %s secs ---\" % (time.time() - start_time))    \n",
    "    y_preds = [1 if e >= 0.5 else 0 for e in y_probs] \n",
    "    #feature_contribs = model.predict(input_data, pred_contribs=True, validate_features=False)\n",
    "    return np.vstack((y_preds, y_probs))\n",
    "\n",
    "\n",
    "def output_fn(predictions, content_type=\"application/json\"):\n",
    "    \"\"\"\n",
    "    After invoking predict_fn, the model server invokes `output_fn`.\n",
    "    \"\"\"\n",
    "    if content_type == \"text/csv\":\n",
    "        return ','.join(str(x) for x in outputs)\n",
    "    elif content_type == \"application/json\":\n",
    "        outputs = json.dumps({\n",
    "            'pred': predictions[0,:].tolist(),\n",
    "            'prob': predictions[1,:].tolist()\n",
    "        })        \n",
    "        \n",
    "        return outputs\n",
    "    else:\n",
    "        raise ValueError(\"Content type {} is not supported.\".format(content_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26dcf78",
   "metadata": {},
   "source": [
    "### Check Inference Results & Debugging\n",
    "\n",
    "로컬 엔드포인트나 호스팅 엔드포인트 배포 전, 로컬 환경 상에서 직접 추론을 수행하여 결과를 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a58c6bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost-model\n"
     ]
    }
   ],
   "source": [
    "!rm -rf model && mkdir model && tar -xzvf model.tar.gz -C model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3010604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = xgb.Booster()\n",
    "model.load_model(\"model/xgboost-model\")\n",
    "\n",
    "test_df = pd.read_csv(f'{DATASET_PATH}/test.csv')\n",
    "y_test = test_df.iloc[:, 0].astype('int')\n",
    "test_df = test_df.drop('fraud', axis=1)\n",
    "dtest = xgb.DMatrix(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7407029b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10092484, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = model.predict(dtest)\n",
    "y_pred = np.array([1 if e >= 0.5 else 0 for e in y_prob])\n",
    "y_prob[0], y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c2412",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 2. Deploy a trained model from Amazon S3\n",
    "---\n",
    "\n",
    "SageMaker API의 `Model` 클래스는 훈련한 모델을 서빙하기 위한 모델 아티팩트와 도커 이미지를 정의합니다. \n",
    "`Model` 클래스 인스턴스 호출 시 AWS에서 사전 빌드한 도커 이미지 URL을 직접 가져올 수도 있지만, Model의 자식 클래스로(예: `XGBoostModel`, `TensorFlowModel`) 초기화하면 파라메터에 버전만 지정하는 것만으로 편리하게 추론을 수행하는 환경을 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7300ce7",
   "metadata": {},
   "source": [
    "### Upload model artifacts to S3\n",
    "압축한 모델 아티팩트를 Amazon S3로 복사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f51977cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model.tar.gz to s3://sagemaker-us-east-1-875385903972/sm-special-webinar/deploy/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "prefix = 'sm-special-webinar/deploy'\n",
    "s3_path = f's3://{bucket}/{prefix}/model.tar.gz'\n",
    "!aws s3 cp model.tar.gz {s3_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471eefc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.1. Deploy to Local Environment: XGBoostModel class\n",
    "\n",
    "SageMaker 호스팅 엔드포인트로 배포하기 전에 로컬 모드 엔드포인트로 배포할 수 있습니다. 로컬 모드는 현재 개발 중인 환경에서 도커 컨테이너를 실행하여 SageMaker 프로세싱/훈련/추론 작업을 에뮬레이트할 수 있습니다. 추론 작업의 경우는 Amazon ECR의 딥러닝 프레임워크 기반 추론 컨테이너를 로컬로 가져오고(docker pull) 컨테이너를 실행하여(docker run) 모델 서버를 시작합니다.\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html\n",
    "\n",
    "```python\n",
    "local_model_path = f'{os.getcwd()}/model'\n",
    "ecr_uri = xgb_image_uri\n",
    "\n",
    "# 도커 컨테이너 구동\n",
    "!docker run --name xgb -itd -p 8080:8080 -v {local_model_path}:/opt/ml/model {ecr_uri} serve\n",
    "\n",
    "# 실시간 호출 테스트 \n",
    "!curl -X POST -H 'Content-Type: application/json' localhost:8080/invocations -d ...\n",
    "\n",
    "# 도커 컨테이너 중지 및 삭제    \n",
    "!docker stop xgb\n",
    "!docker rm xgb\n",
    "```\n",
    "\n",
    "참고로 SageMaker SDK에서 `deploy(...)` 메소드로 엔드포인트 배포 시, 인스턴스 타입을 local 이나 local_gpu로 지정하면 위의 과정을 자동으로 수행할 수 있습니다.\n",
    "\n",
    "```python\n",
    "# 로컬 엔드포인트 배포\n",
    "local_predictor = local_model.deploy(initial_instance_count=1, instance_type=\"local\")\n",
    "\n",
    "# 실시간 호출 테스트 \n",
    "local_predictor.predict(...)\n",
    "\n",
    "# 로컬 엔드포인트 삭제 (도커 컨테이너 중지 및 삭제)\n",
    "local_predictor.delete_endpoint()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dafaf0",
   "metadata": {},
   "source": [
    "아래 코드를 보시면 아시겠지만, 지속적으로 업데이트되는 파이썬 버전&프레임워크 버전&트랜스포머 버전에 쉽게 대응할 수 있습니다. AWS에서 관리하고 있는 딥러닝 컨테이너(DLC) 목록을 아래 주소에서 확인해 보세요.\n",
    "- https://github.com/aws/deep-learning-containers/blob/master/available_images.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a1bd9",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1887eba-5301-4063-9918-7b297c9a14a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_path=\"file:///home/ec2-user/SageMaker/simple-sagemaker/lab_2_serving/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dfcb78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "xgb_model = XGBoostModel(\n",
    "    model_data=s3_path,\n",
    "    role=role,\n",
    "    entry_point=\"src/inference.py\",\n",
    "    framework_version=XGB_FRAMEWORK_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364bb6a0",
   "metadata": {},
   "source": [
    "### Create Endpoint\n",
    "\n",
    "SageMaker SDK는 `deploy(...)` 메소드를 호출 시, `create-endpoint-config`와 `create-endpoint`를 같이 수행합니다. 좀 더 세분화된 파라메터 조정을 원하면 AWS CLI나 boto3 SDK client 활용을 권장 드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93a2ee41-72c8-41ae-abed-6c8fe0e2e467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type='local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5ee6342-99d0-4bab-8ff0-5e00d423dd82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if instance_type in ['local', 'local_gpu']:\n",
    "    from sagemaker.local import LocalSession\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "else:\n",
    "    sagemaker_session = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2abd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to 62dit6aibu-algo-1-k6v67\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m [2023-06-01:06:21:13:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m [2023-06-01:06:21:13:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m [2023-06-01:06:21:13:INFO] nginx config: \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m worker_processes auto;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m daemon off;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m events {\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m }\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m http {\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   }\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   server {\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     }\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     location / {\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     }\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   }\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m }\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m \n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/bin/serve\", line 8, in <module>\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     sys.exit(serving_entrypoint())\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/serving.py\", line 154, in serving_entrypoint\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     server.start(env.ServingEnv().framework_module)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_server.py\", line 86, in start\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     _modules.import_module(env.module_dir, env.module_name)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_modules.py\", line 253, in import_module\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     _files.download_and_extract(uri, _env.code_dir)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_files.py\", line 129, in download_and_extract\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     s3_download(uri, dst)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_files.py\", line 165, in s3_download\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     s3.Bucket(bucket).download_file(key, dst)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/boto3/s3/inject.py\", line 246, in bucket_download_file\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/boto3/s3/inject.py\", line 172, in download_file\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     extra_args=ExtraArgs, callback=Callback)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/boto3/s3/transfer.py\", line 307, in download_file\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     future.result()\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/s3transfer/futures.py\", line 106, in result\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     return self._coordinator.result()\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/s3transfer/futures.py\", line 265, in result\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     raise self._exception\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/s3transfer/tasks.py\", line 255, in _main\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     self._submit(transfer_future=transfer_future, **kwargs)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/s3transfer/download.py\", line 343, in _submit\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     **transfer_future.meta.call_args.extra_args\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/botocore/client.py\", line 357, in _api_call\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     return self._make_api_call(operation_name, kwargs)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/botocore/client.py\", line 676, in _make_api_call\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m     raise error_class(parsed_response, operation_name)\n",
      "\u001b[36m62dit6aibu-algo-1-k6v67 |\u001b[0m botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/image.py\", line 854, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/image.py\", line 916, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/image.py\", line 859, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmpbgsd9pbc/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m62dit6aibu-algo-1-k6v67 exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd036cc",
   "metadata": {},
   "source": [
    "### Check Docker\n",
    "\n",
    "모델 서빙을 위한 도커 컨테이너가 구동되고 있음을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f9fd6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33fa1b",
   "metadata": {},
   "source": [
    "### Prediction - SageMaker SDK & text/csv\n",
    "샘플 데이터에 대해 추론을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a21b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer, NumpySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "xgb_predictor.serializer = CSVSerializer()\n",
    "xgb_predictor.deserializer = JSONDeserializer() \n",
    "\n",
    "outputs = xgb_predictor.predict(test_df.values[0:4,:])\n",
    "y_test_sample = y_test[0:4].values\n",
    "y_pred_sample = outputs['pred']; y_prob_sample = outputs['prob']\n",
    "y_test_sample, y_pred_sample, y_prob_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78f3f4",
   "metadata": {},
   "source": [
    "### Prediction - boto3 SDK & application/x-npy\n",
    "\n",
    "위의 코드 셀처럼 SageMaker SDK의 `predict(...)` 메소드로 추론을 수행할 수도 있지만, 이번에는 boto3의 `invoke_endpoint(...)` 메소드로 추론을 수행해 보겠습니다.\n",
    "Boto3는 서비스 레벨의 저수준(low-level) SDK로, ML 실험에 초점을 맞춰 일부 기능들이 추상화된 고수준(high-level) SDK인 SageMaker SDK와 달리 SageMaker API를 완벽하게 제어할 수 있습으며, 프로덕션 및 자동화 작업에 적합합니다.\n",
    "\n",
    "[Note] `invoke_endpoint(...)` 호출을 위한 런타임 클라이언트 인스턴스 생성 시, 로컬 배포 모드에서는`sagemaker.local.LocalSagemakerRuntimeClient(...)`를 호출해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080259f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "runtime_client = sagemaker.local.LocalSagemakerRuntimeClient()\n",
    "endpoint_name = xgb_model.endpoint_name\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='application/x-npy',\n",
    "    Accept='application/json',\n",
    "    Body=test_df.values[0:4,:].tobytes()\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read().decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d180d",
   "metadata": {},
   "source": [
    "### Prediction - boto3 SDK & text/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from io import StringIO\n",
    "csv_file = io.StringIO()\n",
    "test_df[0:4].to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "payload = csv_file.getvalue()\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='text/csv',\n",
    "    Accept='application/json',\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read().decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadddacf",
   "metadata": {},
   "source": [
    "### Local Mode Endpoint Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()\n",
    "xgb_model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69882923",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.2. Deploy to Local Environment: Model class\n",
    "\n",
    "이번에는 `Model` 클래스로 로컬 환경에서 모델 서빙을 수행합니다. 여러분의 추론 환경을 커스터마이징하여 private ECR에 등록할 때 유용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18643d",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b3d696a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1\n"
     ]
    }
   ],
   "source": [
    "# If you need to create a sagemaker.model.Model, rather than sagemaker.xgboost.model.XGBoostModel\n",
    "image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region, XGB_FRAMEWORK_VERSION)\n",
    "print(image_uri)\n",
    "\n",
    "xgb_model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=s3_path,\n",
    "    role=role,\n",
    "    entry_point=\"src/inference.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d41094",
   "metadata": {},
   "source": [
    "### Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "632d087f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to 3kwxt77r0j-algo-1-ast4y\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m [2023-06-01:06:19:45:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m [2023-06-01:06:19:45:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m [2023-06-01:06:19:45:INFO] nginx config: \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m worker_processes auto;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m daemon off;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m events {\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m }\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m http {\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   }\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   server {\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     }\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     location / {\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     }\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   }\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m }\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m \n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/bin/serve\", line 8, in <module>\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     sys.exit(serving_entrypoint())\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/serving.py\", line 154, in serving_entrypoint\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     server.start(env.ServingEnv().framework_module)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_server.py\", line 86, in start\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     _modules.import_module(env.module_dir, env.module_name)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_modules.py\", line 253, in import_module\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     _files.download_and_extract(uri, _env.code_dir)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_files.py\", line 129, in download_and_extract\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     s3_download(uri, dst)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_files.py\", line 165, in s3_download\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     s3.Bucket(bucket).download_file(key, dst)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/boto3/s3/inject.py\", line 246, in bucket_download_file\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/boto3/s3/inject.py\", line 172, in download_file\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     extra_args=ExtraArgs, callback=Callback)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/boto3/s3/transfer.py\", line 307, in download_file\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     future.result()\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/s3transfer/futures.py\", line 106, in result\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     return self._coordinator.result()\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/s3transfer/futures.py\", line 265, in result\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     raise self._exception\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/s3transfer/tasks.py\", line 255, in _main\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     self._submit(transfer_future=transfer_future, **kwargs)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/s3transfer/download.py\", line 343, in _submit\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     **transfer_future.meta.call_args.extra_args\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/botocore/client.py\", line 357, in _api_call\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     return self._make_api_call(operation_name, kwargs)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m   File \"/miniconda3/lib/python3.7/site-packages/botocore/client.py\", line 676, in _make_api_call\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m     raise error_class(parsed_response, operation_name)\n",
      "\u001b[36m3kwxt77r0j-algo-1-ast4y |\u001b[0m botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/image.py\", line 854, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/image.py\", line 916, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/image.py\", line 859, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmpub2_hy8w/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m3kwxt77r0j-algo-1-ast4y exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xgb_predictor \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/model.py:1298\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1296\u001b[0m     explainer_config_dict \u001b[38;5;241m=\u001b[39m explainer_config\u001b[38;5;241m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1298\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_from_production_variants\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduction_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mproduction_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1310\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:4539\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict)\u001b[0m\n\u001b[1;32m   4536\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating endpoint-config with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m   4537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_options)\n\u001b[0;32m-> 4539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:3899\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   3896\u001b[0m tags \u001b[38;5;241m=\u001b[39m tags \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m   3897\u001b[0m tags \u001b[38;5;241m=\u001b[39m _append_project_tags(tags)\n\u001b[0;32m-> 3899\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEndpointName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEndpointConfigName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\n\u001b[1;32m   3901\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m   3903\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_for_endpoint(endpoint_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/local_session.py:359\u001b[0m, in \u001b[0;36mLocalSagemakerClient.create_endpoint\u001b[0;34m(self, EndpointName, EndpointConfigName, Tags)\u001b[0m\n\u001b[1;32m    357\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m _LocalEndpoint(EndpointName, EndpointConfigName, Tags, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n\u001b[1;32m    358\u001b[0m LocalSagemakerClient\u001b[38;5;241m.\u001b[39m_endpoints[EndpointName] \u001b[38;5;241m=\u001b[39m endpoint\n\u001b[0;32m--> 359\u001b[0m \u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/entities.py:608\u001b[0m, in \u001b[0;36m_LocalEndpoint.serve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mserve(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprimary_container[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelDataUrl\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprimary_container[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnvironment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    605\u001b[0m )\n\u001b[1;32m    607\u001b[0m serving_port \u001b[38;5;241m=\u001b[39m get_config_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal.serving_port\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_session\u001b[38;5;241m.\u001b[39mconfig) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m8080\u001b[39m\n\u001b[0;32m--> 608\u001b[0m \u001b[43m_wait_for_serving_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserving_port\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# the container is running and it passed the healthcheck status is now InService\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m _LocalEndpoint\u001b[38;5;241m.\u001b[39m_IN_SERVICE\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/local/entities.py:949\u001b[0m, in \u001b[0;36m_wait_for_serving_container\u001b[0;34m(serving_port)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57e4ae",
   "metadata": {},
   "source": [
    "### Create Predictor\n",
    "\n",
    "`Model` 클래스로 모델 생성 시, `Predictor` 클래스를 생성하고 직렬화 및 역직렬화 포맷을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "endpoint_name = xgb_model.endpoint_name\n",
    "local_sess = LocalSession()\n",
    "\n",
    "xgb_predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=local_sess,\n",
    "    serializer=CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aece95",
   "metadata": {},
   "source": [
    "### Prediction - SageMaker SDK & text/csv\n",
    "샘플 데이터에 대해 추론을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900509c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "outputs = json.loads(xgb_predictor.predict(test_df.values[0:4,:]))\n",
    "y_test_sample = y_test[0:4].values\n",
    "y_pred_sample = outputs['pred']; y_prob_sample = outputs['prob']\n",
    "y_test_sample, y_pred_sample, y_prob_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79688a6",
   "metadata": {},
   "source": [
    "### Local Mode Endpoint Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_model()\n",
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ba349",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.3. Deploy to Hosting Instance\n",
    "\n",
    "로컬 모드에서 충분히 디버깅했으면 실제 호스팅 인스턴스로 배포할 차례입니다. 코드는 거의 동일하며, `instance_type`만 다르다는 점을 주목해 주세요! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcdcfe",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae35c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "xgb_model = XGBoostModel(\n",
    "    model_data=s3_path,\n",
    "    role=role,\n",
    "    entry_point=\"src/inference.py\",\n",
    "    framework_version=XGB_FRAMEWORK_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd632e",
   "metadata": {},
   "source": [
    "### Create Endpoint\n",
    "\n",
    "SageMaker SDK는 `deploy(...)` 메소드를 호출 시, `create-endpoint-config`와 `create-endpoint`를 같이 수행합니다. 좀 더 세분화된 파라메터 조정을 원하면 AWS CLI나 boto3 SDK client 활용을 권장 드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad942a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge', \n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f911c60",
   "metadata": {},
   "source": [
    "### Wait for the endpoint jobs to complete\n",
    "\n",
    "엔드포인트가 생성될 때까지 기다립니다. 엔드포인트가 가리키는 호스팅 리소스를 프로비저닝하는 데에 몇 분의 시간이 소요됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "def make_endpoint_link(region, endpoint_name, endpoint_task):\n",
    "    endpoint_link = f'<b><a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\">{endpoint_task} Review Endpoint</a></b>'   \n",
    "    return endpoint_link \n",
    "        \n",
    "endpoint_link = make_endpoint_link(region, xgb_predictor.endpoint_name, '[Deploy model from S3]')\n",
    "display(HTML(endpoint_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.wait_for_endpoint(xgb_predictor.endpoint_name, poll=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00697f",
   "metadata": {},
   "source": [
    "### Prediction - SageMaker SDK & text/csv\n",
    "샘플 데이터에 대해 추론을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d32365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer, NumpySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "xgb_predictor.serializer = CSVSerializer()\n",
    "xgb_predictor.deserializer = JSONDeserializer() \n",
    "\n",
    "outputs = xgb_predictor.predict(test_df.values[0:4,:])\n",
    "y_test_sample = y_test[0:4].values\n",
    "y_pred_sample = outputs['pred']; y_prob_sample = outputs['prob']\n",
    "y_test_sample, y_pred_sample, y_prob_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f9424",
   "metadata": {},
   "source": [
    "### Prediction - boto3 SDK & application/x-npy\n",
    "\n",
    "위의 코드 셀처럼 SageMaker SDK의 `predict(...)` 메소드로 추론을 수행할 수도 있지만, 이번에는 boto3의 `invoke_endpoint(...)` 메소드로 추론을 수행해 보겠습니다.\n",
    "Boto3는 서비스 레벨의 저수준(low-level) SDK로, ML 실험에 초점을 맞춰 일부 기능들이 추상화된 고수준(high-level) SDK인 SageMaker SDK와 달리 SageMaker API를 완벽하게 제어할 수 있습으며, 프로덕션 및 자동화 작업에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c472196",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "endpoint_name = xgb_model.endpoint_name\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='application/x-npy',\n",
    "    Accept='application/json',\n",
    "    Body=test_df.values[0:4,:].tobytes()\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read().decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dbfcb",
   "metadata": {},
   "source": [
    "### Prediction - boto3 SDK & text/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d430cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from io import StringIO\n",
    "csv_file = io.StringIO()\n",
    "test_df[0:4].to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "payload = csv_file.getvalue()\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='text/csv',\n",
    "    Accept='application/json',\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read().decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ada7b8",
   "metadata": {},
   "source": [
    "### Evaluation (Not Required)\n",
    "\n",
    "테스트셋에 대해 성능 평가를 수행합니다. 다만, 일반적인 경우 테스트셋은 정답 데이터가 포함되어 있지 않다는 점 유념해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90988dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = xgb_predictor.predict(test_df.values)\n",
    "y_pred = outputs['pred']; y_prob = outputs['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87591ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(f\"{classification_report(y_true=y_test, y_pred=y_pred)}\")\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)     \n",
    "print(cm)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "std = np.std(y_test - y_pred)\n",
    "report_dict = {\n",
    "    \"regression_metrics\": {\n",
    "        \"mse\": {\n",
    "            \"value\": mse,\n",
    "            \"standard_deviation\": std\n",
    "        },\n",
    "    },\n",
    "}\n",
    "report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9824d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "pyplot.plot(fpr, tpr, linestyle='--', label='Fraud')\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.title(f'AUC={auc:.4f}')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e2106",
   "metadata": {},
   "source": [
    "다음 모듈에서 재사용할 변수들을 저장합니다. 만약 다음 모듈로 진행하지 않는다면 아래 섹션의 코드 셀을 주석 해제 후 실행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746aea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store endpoint_name test_df s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84cb564",
   "metadata": {},
   "source": [
    "### (Optional) Endpoint Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_predictor.delete_endpoint()\n",
    "# xgb_model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
